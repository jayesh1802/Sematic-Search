# -*- coding: utf-8 -*-
"""sematic_search.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16ZQ2mf2C_k90RV6Z8caLORK8V4DKoCWC
"""

!ngrok config add-authtoken 2vGMWXrxn69OfjnRRq4urGRPXu1_XCvRa2nVXNtmtnas4gir

!pip install -q fastapi uvicorn sentence-transformers transformers nest_asyncio pyngrok

from fastapi import FastAPI
from pydantic import BaseModel
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline
from typing import List, Dict
import nest_asyncio
import uvicorn

# Required for Colab
nest_asyncio.apply()

app = FastAPI()

# Load sentence transformer model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Load summarization model
summarizer = pipeline("summarization")

class QueryRequest(BaseModel):
    query: str
    questions: List[str]

class SummaryRequest(BaseModel):
    answers: List[str]

@app.post("/similar")
def get_similar(data: QueryRequest):
    query_emb = model.encode(data.query, convert_to_tensor=True)
    question_embs = model.encode(data.questions, convert_to_tensor=True)
    scores = util.cos_sim(query_emb, question_embs)[0]
    top_results = sorted(zip(data.questions, scores), key=lambda x: x[1], reverse=True)[:5]
    return {"results": [{"question": q, "score": float(s)} for q, s in top_results]}

@app.post("/summarize")
def summarize(data: SummaryRequest):
    meaningful_answers = [ans.strip() for ans in data.answers if len(ans.strip().split()) > 3]

    if not meaningful_answers:
        return {"summary": "Not enough information to summarize."}

    combined = " ".join(meaningful_answers)

    summary = summarizer(
        combined,
        max_length=50,
        min_length=10,
        do_sample=False
    )[0]['summary_text']

    return {"summary": summary}

# Tunnel via ngrok
from pyngrok import ngrok
public_url = ngrok.connect(8082)
print(f"Your public Colab API URL: {public_url}")

uvicorn.run(app, port=8082)